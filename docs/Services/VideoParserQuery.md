**Application of the pattern CQRS in the system**

| Component | Responsibility | Operation type | Pros |
|:----------------:|:----------------:|:----------------:|:----------------:|
| Video Parser Service Command | Process the video and stores the frame information in MongoDB (db-combat-events)   | Command | Decopulated from the access to data<br>- It can be optimized for massive persistence |
| Video Parser Service Query   | It expose an endpoint to query frame information by sample_id, game, boss | Query | Optimizated with Streaming chunk for queries that returns a big quantity of documents |

**Importance of CPU in the Video Parser Service Query**

CPU is critical in the Video Parser Service Query, specially for handling high volume queries and complex filters on thousands of frames per video.


**Technics reasons**

* __Deserialization_of_documents__: MongoDB returns BSON, This BSON must be parsed into JSON objects. This requires CPU cycles, above all documents are big or contains nested arrays  like detections array.

* __Use_of_logic_fillters__: Make a query by phase, action, confidence, or sub aggregations kind of $group, $sort, $project demands intensive processing in the service.



**Possible optimizations for mitigate over workload in CPU**

| Strategy | Benefit | Recommendation |
|:----------------:|:----------------:|:----------------:|
| **Índexes in MongoDB** | Reduce the volume of scanned documents | Indexing  by sample_id, game, boss |
| **Specific projections** | Only query the necessary data | Avoid query the complete detections array if not necessary |
| **Workers in parallel** | Scales the CPU horizontally | The service can run with multiple threads/instances | 

**Streaming with chunked response**

The streaming with chunked response is a technique that allows sending data in chunks while these are processed, instead of waiting until the query finishes. This is especially useful for handling big data volumes like the thousands of documents generated by analyzing the video.

**Advantages of streaming**

* Latency reduction: The data begins to be sent so soon as be available, performing the user experience.

* Tolerance to fail: If the connection is interrupted, the client can start from the last received chunk.

**Technic implementation**

1. Configuration of the receptor: be sure that the Pattern Analyzer Service supports chunked responses.

2. Split the data in chunks: Split the documents in blocks(EJ, 100 documents by chunk).

3. Error handling: Implement logic for retry or resume the transmission in case of failure.

**Important note**

In this case, frames will not be sent by streaming for renderization purposes, instead frames will be sent MongoDB documents with all the detected actions by YOLO in the frames. This ensures that the client will receive processed and structured information, optimizing the resources used and the user experience.

**Using streaming in the Pattern Analyzer Service**

The streaming will be used by the Pattern Analyzer Service in order to work with the data to search patterns. This service will process the data internally to identify recurrent patterns and generate tactic insights. This avoids time outs in the responses from Video Parser Query. 
The way in which Pattern Analyzer Service knows which information request, is through the event published in a queue from RabbitMQ, In this event Pattern Analyzer Service will be informed about a new video that is already processed and the extracted information is ready to be analyzed.

This event contains at least the sample_id, game and boss form the video that was processed. Also It can include util metadata like video duration, processed total frames, or a timestamp of finalization.

When the pattern-analyzer receives the event, it requests the stream to the video-parser-query with the sample_id, game and boss as parameters previously obtained in the event queue; now the pattern-analyzer knows exactly which video needs to be analyzed.




**Aplicación del patrón CQRS al sistema**

| Componente | Responsabilidad | Tipo de operación | Ventajas |
|:----------------:|:----------------:|:----------------:|:----------------:|
| Video Parser Service Command | Procesa el video y almacena los frames en MongoDB (db-combat-events)   | Command | Desacoplado del acceso a datos<br>- Puede optimizarse para escritura masiva |
| Video Parser Service Query   | Expone endpoint para consultar frames por sample_id, game, boss | Query | Optimizado con Streaming chunk para consultas que retornan gran cantidad de documentos |

**Importancia del CPU en el Video Parser Service Query**

El CPU es crítico en el Video Parser Service Query, especialmente para manejar consultas de alto volumen y filtros complejos sobre miles de frames por video.

**Razones técnicas**

* __Deserialización_de_documentos__: MongoDB devuelve BSON, que debe transformarse a objetos JSON. Esto requiere ciclos del CPU, sobre todo si los documentos son grandes o tienen arrays anidados como detections.

* __Aplicación_de_filtros_lógicos__: Consultas por phase, action, confidence, o incluso subagregaciones tipo $group, $sort, $project demandan procesamiento intensivo en el servicio.


**Optimizaciones posibles para mitigar la carga del CPU**

| Estrategia | Beneficio | Recomendación |
|:----------------:|:----------------:|:----------------:|
| **Índices en MongoDB** | Reduce el volumen de documentos escaneados | Indexar por sample_id, game, boss |
| **Proyecciones específicas** | Solo se consulta lo necesario | Evita consultar el array completo de detections si no se usa |
| **Workers en paralelo** | Escala el CPU horizontalmente | El servicio puede correr con múltiples threads/instancias | 

**Streaming con chunked response**

El streaming con chunked response es una técnica que permite enviar datos en partes (cunks) mientras se procesan, en lugar de esperar a que toda la consulta termine. Esto es especialmente útil para manejar grandes volúmenes de datos como los miles de documentos generados por analizar el video.

**Ventajas del streaming**

* Reducción de latencia: Los datos comienzan a enviarse tan pronto como están disponibles, mejorando la experiencia del usuario.

* Tolerancia a fallos: Si la conexión se interrumpe, el cliente puede reanudar desde el último chunk recibido.

**Implementación técnica**

1. Configuración del microservicio receptor: Asegúrarse de que el Pattern Analyzer Service soporte respuestas chunked.

2. División de datos en chunks: Dividir los documentos en bloques manejables (por ejemplo, 100 documentos por chunk).

3. Manejo de errores: Implementar lógica para reintentar o reanudar la transmisión en caso de fallos.

**Nota importante**

En este caso, no se enviarán los frames por streaming para ser renderizados, sino que serán documentos de MongoDB con las acciones detectadas por YOLO en los frames. Esto asegura que el cliente reciba información procesada y estructurada, optimizando el uso de recursos y la experiencia del usuario.

**Uso del streaming en el Pattern Analyzer Service**

El streaming será utilizado por el Pattern Analyzer Service para trabajar con los datos en busca de patrones. Este servicio los procesará internamente para identificar patrones recurrentes y generar insights tácticos. Esto evita time outs debido a la naturaleza de la respuestas del Video Parser Query. 
La manera en que el Pattern Analyzer Service sabra que inofrmacion pedir, sera atra vez de un evento publicado en una cola de RabbitMQ, en el cual se le informara que un video acaba de ser procesado y la informacion extraida esta lista para ser analizada.

Este evento contendrá almenos el sample_id, game y boss del video que acaba de ser procesado. Podría incluir también metadatos útiles como la duración del video, el número total de frames procesados, o un timestamp de finalización.

Cuando pattern-analyzer recibe el evento, solicita el stream de datos al video-parser-query con el sample_id, game y boss obtenidos del evento de la cola, el pattern-analyzer ahora sabe exactamente qué video necesita analizar.
